{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "w6K7xa23Elo4",
        "mDgbUHAGgjLW",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "1UUpS68QDMuG",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShrirangGhode/Yhills/blob/main/ML_Email_Campaign_Prediction_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Team\n",
        "##### **Team Member 1 -** Purva Kulkarni\n",
        "##### **Team Member 2 -** Shrirang Ghode"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Email marketing stands as a pivotal strategy for businesses to maintain a direct line of communication with their customers, delivering updates, product information, and important notices directly to their inboxes. It serves not only as a promotional tool but as a means to cultivate relationships with leads, new customers, and past customers. Emails, with their potential for personalized messaging and strategic approaches, are recognized as one of the most influential marketing channels.\n",
        "\n",
        "While individuals often subscribe to various business emails for practical reasons such as digital receipts and updates, the challenge lies in ensuring that these emails capture and maintain the attention of the recipients. The likelihood of emails being ignored is influenced by factors such as unclear structure, excessive images, numerous links, complex language, or excessive length.\n",
        "\n",
        "In this project, the objective is to develop machine learning models that effectively characterize and predict whether an email is likely to be ignored, read, or acknowledged by the recipient. Beyond prediction, the goal is to conduct a comprehensive analysis to identify the key features that significantly impact whether an email captures the reader's attention or gets overlooked."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here.\n",
        "\n",
        "Shrirang Ghode  https://github.com/ShrirangGhode/Email_Campaign_Prediction/tree/main"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the dynamic landscape of small to medium businesses, effective email marketing is a pivotal strategy for engaging prospective customers and converting them into long-term leads. Gmail, being a widely used platform, serves as a primary channel for communication. However, the challenge lies in optimizing email campaigns to understand and improve recipient engagement.\n",
        "\n",
        "The main objective of this project is to develop a machine learning model that characterizes emails based on recipient actions, aiming to categorize emails into three primary states: \"Ignored,\" \"Read,\" and \"Acknowledged.\" These states represent different levels of engagement, providing valuable insights for businesses to tailor their email marketing strategies effectively."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#to ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/project datasets/data_email_campaign.csv'"
      ],
      "metadata": {
        "id": "wXv-lFhT1foT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "6hbU1Rmb1fuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "zV1yoLOG1rKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "# Calculate the missing value counts\n",
        "missing_values = df.isnull().sum()\n",
        "missing_values"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "# Create a bar plot of missing values\n",
        "try:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    ax = sns.barplot(x=missing_values.index, y=missing_values.values)\n",
        "    ax.set_ylim(0, max(missing_values.values) + 10)  # Set y-axis limits\n",
        "    plt.title(\"Missing Values Count\")\n",
        "    plt.xlabel(\"Variables\")\n",
        "    plt.ylabel(\"Missing Value Count\")\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    print(\"Error occurred while visualizing missing values:\", str(e))"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate null value percentages for the specified columns\n",
        "columns_to_check = ['Customer_Location', 'Total_Past_Communications', 'Total_Links', 'Total_Images']\n",
        "\n",
        "null_percentages = {}\n",
        "total_rows = len(df)\n",
        "\n",
        "for column in columns_to_check:\n",
        "    null_count = df[column].isnull().sum()\n",
        "    null_percentage = (null_count / total_rows) * 100\n",
        "    null_percentages[column] = null_percentage\n",
        "\n",
        "# Display null value percentages\n",
        "for column, percentage in null_percentages.items():\n",
        "    print(f\"Null percentage in '{column}': {percentage:.2f}%\")\n"
      ],
      "metadata": {
        "id": "iHibD7Ic12y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The target variable is \"Email Status,\" which indicates whether the email was ignored, read, or acknowledged by the reader. This is likely a categorical variable.\n",
        "Features:\n",
        "\n",
        "The dataset includes a variety of features, both categorical and continuous, providing diverse information about each email.\n",
        "Categorical Features:\n",
        "\n",
        "Categorical features include \"Email Type,\" \"Email Source,\" \"Email Campaign Type,\" \"Customer Location,\" and \"Time Sent Category.\"\n",
        "Continuous Features:\n",
        "\n",
        "Continuous features encompass \"Subject Hotness Score,\" \"Total Past Communications,\" \"Word Count,\" \"Total Links,\" and \"Total Images.\"\n",
        "Email ID:\n",
        "\n",
        "Email ID serves as an identifier for each customer's email.\n",
        "Nature of Features:\n",
        "\n",
        "Features such as \"Subject Hotness Score,\" \"Word Count,\" \"Total Links,\" and \"Total Images\" provide insights into the content and structure of the emails.\n",
        "Contextual Features:\n",
        "\n",
        "Features like \"Email Type,\" \"Email Source,\" and \"Email Campaign Type\" give context about the nature and purpose of the emails.\n",
        "Temporal Feature:\n",
        "\n",
        "\"Time Sent Category\" provides information about the time of day when the email was sent.\n",
        "Customer Location:\n",
        "\n",
        "\"Customer Location\" adds a demographic aspect, specifying the location of the customer.\n",
        "Total Past Communications:\n",
        "\n",
        "This feature indicates the historical interaction by representing the total number of past communications from the same source.\n",
        "Understanding the dataset's features and their characteristics is crucial for the development of machine learning models that aim to predict and understand the engagement level of emails. Further exploration, cleaning, and analysis of the dataset will be necessary to uncover patterns and relationships within the data"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Email Id** - It contains the email id's of the customers/individuals\n",
        "* **Email Type** - There are two categories 1 and 2. We can think of them as marketing emails or important updates, notices like emails regarding the business.\n",
        "* **Subject Hotness Score** - It is the email's subject's score on the basis of how good and effective the content is.\n",
        "* **Email Source** - It represents the source of the email like sales and marketing or important admin mails related to the product.\n",
        "* **Email Campaign Type** - The campaign type of the email.\n",
        "* **Total Past Communications** - This column contains the total previous mails from the same source, the number of communications had.\n",
        "* **Customer Location** - Contains demographical data of the customer, the location where the customer resides.\n",
        "* **Time Email sent Category** - It has three categories 1,2 and 3; the time of the day when the email was sent, we can think of it as morning, evening and night time slots.\n",
        "* **Word Count** - The number of words contained in the email.\n",
        "* **Total links** - Number of links in the email.\n",
        "* **Total Images** - Number of images in the email.\n",
        "* **Email Status** - Our target variable which contains whether the mail was ignored, read, acknowledged by the reader."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "print(\"No of Unique values present in each colum are - \\n\")\n",
        "for column in df.columns:\n",
        "    unique_count = df[column].nunique()\n",
        "    print( column, \":\", unique_count)\n"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# column names and their corresponding unique value counts\n",
        "columns = [\n",
        "    'Email_ID', 'Email_Type', 'Subject_Hotness_Score', 'Email_Source_Type',\n",
        "    'Customer_Location', 'Email_Campaign_Type', 'Total_Past_Communications',\n",
        "    'Time_Email_sent_Category', 'Word_Count', 'Total_Links',\n",
        "    'Total_Images', 'Email_Status'\n",
        "]\n",
        "\n",
        "unique_values = {}\n",
        "for column in columns:\n",
        "    unique_values[column] = df[column].nunique()\n",
        "\n",
        "# Display unique values for each column\n",
        "for column, count in unique_values.items():\n",
        "    print(f\"Column '{column}' has {count} unique value(s):\")\n",
        "    if count < 10:  # If unique values are less, print them\n",
        "        print(df[column].unique())\n",
        "    else:\n",
        "        print(\"Too many unique values to display.\")\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "3p3GlRO42qy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready."
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a pastel color palette\n",
        "pastel_palette = sns.color_palette(\"pastel\")"
      ],
      "metadata": {
        "id": "XzLCYiO92zLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Bar chart for Email_Type vs. Email_Status\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='Email_Type', hue='Email_Status', data=df, palette=pastel_palette)\n",
        "plt.title('Email Type vs. Email Status')\n",
        "plt.xlabel('Email Type')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(title='Email Status')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a bar chart because it is effective for comparing the distribution of categorical variables, in this case, the relationship between Email Type and Email Status. The use of different colors (hue) allows for a clear representation of the counts for each Email Status within each Email Type."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart reveals the distribution of Email Status within each Email Type. Specifically, for Email Type 1, Email Status 0 has the highest count, followed by Email Status 1 and then Email Status 2. The same pattern is observed for Email Type 2, where Email Status 0 has the highest count, followed by Email Status 1 and then Email Status 2. Additionally, it's noted that the count of Email Status in Email Type 1 is generally higher than in Email Type 2."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights suggest that Email Status 0 is the most common across both Email Types. Understanding the distribution can help in optimizing strategies related to Email Type and Email Status. For example, if Email Status 0 is a positive outcome (e.g., successful email delivery), the business can focus on optimizing factors that contribute to this status. This could potentially lead to a positive impact on email delivery rates and overall communication effectiveness.\n",
        "\n",
        "There doesn't seem to be any immediate indication of negative growth from the provided information. However, it's important to consider other relevant factors and business goals to make a comprehensive assessment. If specific Email Status values are associated with negative outcomes (e.g., undelivered emails or low response rates), further analysis might be needed to understand the causes and address any potential issues."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar chart for Email_Source_Type vs. Email_Status\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='Email_Source_Type', hue='Email_Status', data=df, palette=pastel_palette)\n",
        "plt.title('Email Source Type vs. Email Status')\n",
        "plt.xlabel('Email Source Type')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(title='Email Status')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to the first graph, I chose a bar chart because it effectively displays the distribution of categorical variables. In this case, it helps visualize the relationship between Email Source Type and Email Status. The use of different colors (hue) allows for a clear comparison of the counts for each Email Status within each Email Source Type.\n"
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart reveals the distribution of Email Status within each Email Source Type. Specifically, for both Email Source Type 1 and Type 2, Email Status 0 has the highest count, followed by Email Status 1 and then Email Status 2. Additionally, the count of Email Status in Email Source Type 1 is slightly higher than in Email Source Type 2."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights can inform strategies related to Email Source Type and Email Status. If, for example, Email Status 0 represents successful outcomes, the business might want to focus on understanding and replicating the factors contributing to this status, especially in Email Source Type 1 where the count is slightly higher.\n",
        "\n",
        "From the provided information, there doesn't appear to be any immediate indication of negative growth. However, it's crucial to consider the broader context, business goals, and potentially conduct further analysis to understand the factors influencing the distribution of Email Status. Negative growth could arise if certain Email Status values are associated with undesirable outcomes, and addressing these issues might be necessary."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar chart for Email_Campaign_Type vs. Email_Status\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='Email_Campaign_Type', hue='Email_Status', data=df, palette=pastel_palette)\n",
        "plt.title('Email Campaign Type vs. Email Status')\n",
        "plt.xlabel('Email Campaign Type')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(title='Email Status')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bar chart is appropriate for comparing the distribution of categorical variables, such as Email Campaign Type and Email Status. The use of different colors (hue) helps in visualizing the counts of each Email Status within each Email Campaign Type."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart indicates the distribution of Email Status within each Email Campaign Type. Specifically: In Email Campaign Type 1, there is a very low count for all three Email Status categories. In Email Campaign Type 2, Email Status 0 has the highest count, followed by Email Status 1 and then Email Status 2. In Email Campaign Type 3, Email Status 0 has the highest count, followed by Email Status 1 and then Email Status 2. Overall, Email Campaign Type 2 has the highest count, Email Campaign Type 3 has a lower count, and Email Campaign Type 1 has the lowest count."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights can guide decisions related to email campaign strategies. For instance, understanding that Email Campaign Type 2 generally leads to a higher count of successful outcomes (Email Status 0) can inform the allocation of resources and efforts toward similar campaign types. It suggests that Email Campaign Type 2 may be more effective in achieving positive results.\n",
        "\n",
        "The low count of all three Email Status categories in Email Campaign Type 1 might be a concern. If Email Campaign Type 1 is intended to be a significant part of the strategy, the business might need to investigate the reasons for this low count. It could be due to various factors such as ineffective content, targeting issues, or technical problems. Addressing these issues could potentially lead to improved outcomes."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar chart for Time_Email_sent_Category vs. Email_Status\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='Time_Email_sent_Category', hue='Email_Status', data=df, palette=pastel_palette)\n",
        "plt.title('Time Email Sent Category vs. Email Status')\n",
        "plt.xlabel('Time Email Sent Category')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(title='Email Status')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bar chart is suitable for comparing the distribution of categorical variables, in this case, the relationship between Time Email Sent Category and Email Status. The use of different colors (hue) allows for a clear visualization of the counts for each Email Status within each Time Email Sent Category."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows the distribution of Email Status within each Time Email Sent Category. Specifically: Time Email Sent Category 2 has the highest count. Time Email Sent Categories 1 and 3 have approximately the same count. In all three Time Email Sent Categories, Email Status 0 has the highest count, followed by Email Status 1 and then Email Status 2."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights can be valuable for optimizing the timing of email campaigns. Knowing that Time Email Sent Category 2 has the highest count of successful outcomes (Email Status 0) might suggest that this time category is more effective for engagement. The business can consider focusing on this time category for important communications.\n",
        "\n",
        "There isn't immediate evidence of negative growth from the provided information. However, it's important to consider additional factors and business goals. If there are specific Email Status values associated with negative outcomes, a more in-depth analysis may be needed to understand the causes and address any potential issues."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**For Numerical Variables**"
      ],
      "metadata": {
        "id": "o0z36DrZQGYu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter plot of 'Subject_Hotness_Score' vs. 'Total_Past_Communications' with color encoding by 'Email_Status'\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x='Subject_Hotness_Score', y='Total_Past_Communications', hue='Email_Status', data=df)\n",
        "plt.title('Subject Hotness Score vs. Total Past Communications')\n",
        "plt.xlabel('Subject Hotness Score')\n",
        "plt.ylabel('Total Past Communications')\n",
        "plt.legend(title='Email Status')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a scatter plot because it is effective for visualizing the relationship between two continuous variables, in this case, 'Subject_Hotness_Score' and 'Total_Past_Communications'. The color encoding by 'Email_Status' adds an extra dimension, allowing for the exploration of how the email status varies across different combinations of the two variables."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scatter plot shows that there is no clear linear relationship between 'Subject_Hotness_Score' and 'Total_Past_Communications'. The spread of points suggests a right skewness, indicating that there might be a concentration of data points at lower values of 'Total_Past_Communications' and 'Subject_Hotness_Score'. The color encoding by 'Email_Status' helps identify how the email status varies within different regions of the scatter plot."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights suggest that the relationship between 'Subject_Hotness_Score' and 'Total_Past_Communications' may not be straightforward. Further analysis or feature engineering might be needed to better understand the patterns and determine how these variables influence email status. This understanding could potentially lead to more targeted and effective communication strategies\n",
        "\n",
        "There isn't a clear indication of negative growth from the provided information. However, the right skewness in the spread of points might indicate a concentration of data in certain regions, and it's essential to explore whether this concentration is associated with specific Email_Status values. Negative growth could arise if certain combinations of 'Subject_Hotness_Score' and 'Total_Past_Communications' are consistently associated with undesirable email statuses."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "# Scatter plot of 'Subject_Hotness_Score' vs. 'Word_Count' with color encoding by 'Email_Status'\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x='Subject_Hotness_Score', y='Word_Count', hue='Email_Status', data=df)\n",
        "plt.title('Subject Hotness Score vs. Word Count')\n",
        "plt.xlabel('Subject Hotness Score')\n",
        "plt.ylabel('Word Count')\n",
        "plt.legend(title='Email Status')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to the previous scatter plot, I chose a scatter plot because it effectively visualizes the relationship between two continuous variables, 'Subject_Hotness_Score' and 'Word_Count'. The color encoding by 'Email_Status' adds an extra dimension, allowing for the exploration of how the email status varies across different combinations of the two variables."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scatter plot shows that there is no clear linear relationship between 'Subject_Hotness_Score' and 'Word_Count'. The points are scattered without forming a discernible pattern. The color encoding by 'Email_Status' helps identify how the email status varies within different regions of the scatter plot."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights suggest that the relationship between 'Subject_Hotness_Score' and 'Word_Count' may not be straightforward. Further analysis or feature engineering might be needed to better understand the patterns and determine how these variables influence email status. Understanding these relationships could help in refining communication strategies.\n",
        "\n",
        "There isn't a clear indication of negative growth from the provided information. The lack of a linear relationship between the variables doesn't inherently imply negative growth. However, it's crucial to explore whether specific combinations of 'Subject_Hotness_Score' and 'Word_Count' are consistently associated with undesirable email statuses. Negative growth could arise if certain patterns in these variables are linked to negative outcomes."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "# Scatter plot of 'Subject_Hotness_Score' vs. 'Total_Links' with color encoding by 'Email_Status'\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x='Subject_Hotness_Score', y='Total_Links', hue='Email_Status', data=df)\n",
        "plt.title('Subject Hotness Score vs. Total Links')\n",
        "plt.xlabel('Subject Hotness Score')\n",
        "plt.ylabel('Total Links')\n",
        "plt.legend(title='Email Status')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I selected a scatter plot for this visualization because it is effective for exploring the relationship between two continuous variables, in this case, 'Subject_Hotness_Score' and 'Total_Links'. The color encoding by 'Email_Status' allows for an examination of how the email status varies across different combinations of the two variables."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scatter plot indicates that there is no clear linear relationship between 'Subject_Hotness_Score' and 'Total_Links'. The points are scattered across the plot without forming a distinct pattern. The color encoding by 'Email_Status' provides insight into how the email status is distributed within different regions of the scatter plot."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While there may not be a straightforward linear relationship, the insights gained from this scatter plot can help in understanding the variability of email status across different levels of 'Subject_Hotness_Score' and 'Total_Links'. Further analysis or feature engineering may be necessary to uncover more nuanced patterns that could inform targeted communication strategies.\n",
        "\n",
        "There is no immediate indication of negative growth from the provided information. However, it's important to explore whether certain combinations of 'Subject_Hotness_Score' and 'Total_Links' are consistently associated with undesirable email statuses. Negative growth could arise if specific patterns in these variables are linked to negative outcomes."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "# Scatter plot of 'Subject_Hotness_Score' vs. 'Total_Images' with color encoding by 'Email_Status'\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x='Subject_Hotness_Score', y='Total_Images', hue='Email_Status', data=df)\n",
        "plt.title('Subject Hotness Score vs. Total Images')\n",
        "plt.xlabel('Subject Hotness Score')\n",
        "plt.ylabel('Total Images')\n",
        "plt.legend(title='Email Status')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I opted for a scatter plot as it effectively visualizes the relationship between two continuous variables, 'Subject_Hotness_Score' and 'Total_Images'. The color encoding by 'Email_Status' allows for an exploration of how the email status varies across different combinations of the two variables."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scatter plot shows no clear linear relationship between 'Subject_Hotness_Score' and 'Total_Images'. The points are scattered across the plot without forming a discernible pattern. The color encoding by 'Email_Status' provides insight into how the email status is distributed within different regions of the scatter plot."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although there isn't a straightforward linear relationship, the insights gained from this scatter plot can help in understanding the variability of email status across different levels of 'Subject_Hotness_Score' and 'Total_Images'. Further analysis or feature engineering may be needed to uncover more nuanced patterns that could inform targeted communication strategies.\n",
        "\n",
        "There is no immediate indication of negative growth from the provided information. However, it's crucial to explore whether certain combinations of 'Subject_Hotness_Score' and 'Total_Images' are consistently associated with undesirable email statuses. Negative growth could arise if specific patterns in these variables are linked to negative outcomes."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "\n",
        "# Scatter plot of 'Total_Links' vs. 'Total_Images' with color encoding by 'Email_Status'\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x='Total_Links', y='Total_Images', hue='Email_Status', data=df)\n",
        "plt.title('Total Links vs. Total Images')\n",
        "plt.xlabel('Total Links')\n",
        "plt.ylabel('Total Images')\n",
        "plt.legend(title='Email Status')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gA8l4bzI5Op9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scatter plot was chosen because it effectively visualizes the relationship between two numerical variables, 'Total_Links' and 'Total_Images,' while also incorporating color encoding ('Email_Status') to provide additional information. Scatter plots are particularly useful for identifying patterns, correlations, and clusters in data."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a linear relationship between the variables tells us that as the value of one variable (e.g., 'Total_Links') increases, the other variable (e.g., 'Total_Images') also tends to increase proportionally."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Impact:\n",
        "\n",
        "Optimization Opportunities: The insight into a linear relationship between 'Total_Links' and 'Total_Images' may present optimization opportunities. For example, businesses could use this information to streamline their email content creation processes. If increasing the number of links in an email corresponds to an increase in the number of images, marketers can strategically design emails to achieve desired engagement levels. Negative Growth Justification:\n",
        "\n",
        "Potential Overhead: While the linear relationship itself may not indicate negative growth, businesses need to be cautious about potential overhead. If there's a linear relationship but no significant positive impact on user engagement or conversion, increasing both links and images might result in higher costs (e.g., in terms of content creation, data storage, and email sending resources) without a proportional benefit."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming your data is stored in a DataFrame named 'data'\n",
        "# Replace 'data' with your actual DataFrame name\n",
        "\n",
        "# Numeric columns\n",
        "numeric_columns = [\n",
        "    'Email_Type', 'Subject_Hotness_Score', 'Email_Source_Type',\n",
        "    'Email_Campaign_Type', 'Total_Past_Communications',\n",
        "    'Time_Email_sent_Category', 'Word_Count', 'Total_Links',\n",
        "    'Total_Images', 'Email_Status'\n",
        "]\n",
        "\n",
        "# Create histograms for numeric variables\n",
        "for column in numeric_columns:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.hist(df[column], bins=20, color='skyblue', edgecolor='black')\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title(f'Histogram of {column}')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Histograms are chosen for this visualization as they provide a clear representation of the distribution of numerical variables. They are suitable for understanding the frequency distribution of each variable and identifying patterns or trends."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The histograms provide insights into the distribution of various numerical variables: 1)Histogram of 'Email_Type': Email Type 1 has a higher count than Email Type 2.\n",
        "\n",
        "2)Histogram of 'Subject_Hotness_Score': Shows a right-skewed distribution, indicating a concentration of lower scores.\n",
        "\n",
        "3)Histogram of 'Email_Source_Type': Email Source Type 1 has a higher count than Type 2.\n",
        "\n",
        "4)Histogram of 'Email_Campaign_Type': Type 2 has the highest count, followed by Type 3 and then Type 1.\n",
        "\n",
        "5)Histogram of 'Total_Past_Communications': Shows a normal distribution.\n",
        "\n",
        "6)Histogram of 'Time_Email_sent_Category': Type 2 has the highest count, and Types 1 and 3 have a similar count.\n",
        "\n",
        "7)Histogram of 'Word_Count': Shows a normal distribution.\n",
        "\n",
        "8)Histogram of 'Total_Links': Shows a right-skewed distribution.\n",
        "\n",
        "9)Histogram of 'Total_Images': Shows a right-skewed distribution.\n",
        "\n",
        "10)Histogram of 'Email_Status': Type 0 has the highest count, followed by Type 1, and Type 2 has the lowest count."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights from the histograms can be valuable for understanding the distribution of various features, which may inform decisions related to communication strategies, campaign targeting, and content optimization.\n",
        "\n",
        "There isn't an immediate indication of negative growth from the provided information. However, if specific patterns in the histograms are associated with undesirable outcomes, further investigation and analysis would be necessary to understand the causes and potential negative impacts."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "\n",
        "# Create subplots for box plots\n",
        "fig, axes = plt.subplots(3, 2, figsize=(14, 12))\n",
        "\n",
        "# Flatten the axes for easy iteration\n",
        "axes = axes.flatten()\n",
        "\n",
        "# List of numerical columns\n",
        "numerical_columns = ['Subject_Hotness_Score', 'Total_Past_Communications', 'Word_Count', 'Total_Links', 'Total_Images']\n",
        "\n",
        "# Create box plots for each numerical variable with hue by Email_Status\n",
        "for i, column in enumerate(numerical_columns):\n",
        "    sns.boxplot(x='Email_Status', y=column, data=df, ax=axes[i])\n",
        "    axes[i].set_title(f'Boxplot of {column} by Email Status')\n",
        "    axes[i].set_xlabel('Email Status')\n",
        "    axes[i].set_ylabel(column)\n",
        "\n",
        "# Adjust layout and show plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Box plots are chosen for this visualization as they provide a concise summary of the distribution of numerical variables across different categories, in this case, 'Email_Status'. They are particularly useful for identifying the presence of outliers and comparing the central tendency and spread of the data."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the number of Total_Past_Communication is increasing, the chances of Email getting ignored is decreasing.\n",
        "\n",
        "As the word_count increases beyond the 600 mark we see that there is a high possibility of that email being ignored.\n",
        "\n",
        "The box plots provide insights into the distribution of several numerical variables ('Subject_Hotness_Score', 'Total_Past_Communications', 'Word_Count', 'Total_Links', 'Total_Images') across different Email Status categories: The boxplot of 'Total_Images' by 'Email_Status' has a high number of outliers compared to other box plots. The boxplot of 'Subject_Hotness_Score' by 'Email_Status' has the second-highest number of outliers. The boxplot of 'Total_Links' by 'Email_Status' also shows a noticeable number of outliers. The boxplot of 'Total_Past_Communications' by 'Email_Status' has a relatively lower number of outliers. The boxplot of 'Word_Count' by 'Email_Status' has no outliers.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights from the box plots can help in understanding the distribution of numerical variables across different Email Status categories. This understanding may be valuable for decision-making and optimizing communication strategies. For example, identifying outliers can highlight potential issues or exceptional cases that may require special attention.\n",
        "\n",
        "The high number of outliers in the boxplot of 'Total_Images' by 'Email_Status' could potentially raise concerns, as outliers might represent unusual or unexpected patterns. Further investigation into the nature of these outliers and their impact on email performance may be necessary to address any negative growth associated with these cases."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "\n",
        "# Compute the correlation matrix\n",
        "corr_matrix = df.corr()\n",
        "\n",
        "    # Create a heatmap\n",
        "plt.figure(figsize=(18, 10))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True, annot_kws={\"size\": 8})\n",
        "\n",
        "    # Set the title of the chart\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "\n",
        "    # Adjust layout to prevent overlapping values\n",
        "plt.tight_layout()\n",
        "\n",
        "    # Show the chart\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correlation heatmap is chosen because it provides a visual representation of the correlation coefficients between all pairs of numerical variables in the dataset. This helps in identifying potential relationships and dependencies between the variables."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correlation heatmap shows the correlation coefficients between pairs of numerical variables. Here are some potential insights: Positive correlations (values closer to 1) indicate a positive linear relationship, while negative correlations (values closer to -1) indicate a negative linear relationship. Strong correlations are visible between certain pairs of variables, suggesting potential dependencies. The color intensity and the values in the heatmap provide information about the strength and direction of the correlations."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "\n",
        "numerical_columns = ['Email_Type', 'Email_Source_Type','Email_Campaign_Type', 'Time_Email_sent_Category', 'Subject_Hotness_Score', 'Total_Past_Communications', 'Word_Count', 'Total_Links', 'Total_Images', 'Email_Status']\n",
        "\n",
        "# Create a DataFrame with only the numerical columns\n",
        "numerical_df = df[numerical_columns]\n",
        "\n",
        "# Visualize pair plot for numerical variables\n",
        "sns.pairplot(numerical_df)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pair plot is chosen because it provides scatterplots for all pairs of numerical variables in the dataset. This allows for a comprehensive visual examination of relationships between variables."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pair plot reveals scatterplots for all combinations of numerical variables. Based on the provided information: The scatterplots show the relationships between different pairs of variables. Specifically, there is a note about a linear relationship between 'Total_Images' and 'Total_Links.'"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis.\n",
        "\n",
        "###**Null Hypothesis (H):**\n",
        "\"Subject Hotness Score has no significant impact on the likelihood of Email Status being 'Read/Acknowledged' or 'Ignored'\n",
        "\n",
        "###**Alternative Hypothesis (H):**\n",
        "\"Subject Hotness Score has a significant impact on the likelihood of Email Status being 'Read/Acknowledged' or 'Ignored'"
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test.\n",
        "\n",
        "The logistic regression model helps assess the significance of the Subject Hotness Score variable on predicting the likelihood of Email_Status being 'Read' or 'Acknowledged'. The p-value associated with the Subject Hotness Score coefficient in the logistic regression model helps determine if it is statistically significant."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "# Convert Email Status into a binary outcome: 1 for 'Read' and 'Acknowledged', 0 for 'Ignored'\n",
        "df['Email_Status_Binary'] = df['Email_Status'].apply(lambda x: 1 if x in [1, 2] else 0)\n",
        "\n",
        "# Add intercept term\n",
        "df['Intercept'] = 1\n",
        "\n",
        "# Define independent variables (Subject Hotness Score) and dependent variable (Email Status)\n",
        "X = df[['Intercept', 'Subject_Hotness_Score']]\n",
        "y = df['Email_Status_Binary']\n",
        "\n",
        "# Fit logistic regression model\n",
        "logit_model = sm.Logit(y, X)\n",
        "try:\n",
        "    result = logit_model.fit()\n",
        "    # Get the summary of the logistic regression model\n",
        "    print(result.summary())\n",
        "\n",
        "    # Get Z observed statistic\n",
        "    z_observed = result.params['Subject_Hotness_Score'] / result.bse['Subject_Hotness_Score']\n",
        "    print(f\"Z observed: {z_observed}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while fitting the model: {e}\")\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation**:\n",
        "\n",
        "\n",
        "This indicates that the Subject Hotness Score has a statistically significant impact on the likelihood of the Email Status being 'Read' or 'Acknowledged' (in comparison to 'Ignored')\n",
        "\n",
        "As the Z observed statistic is substantially different from zero and the associated p-value is very low, it suggests strong evidence against the null hypothesis and supports the alternative hypothesis that Subject Hotness Score has a significant impact on Email Status."
      ],
      "metadata": {
        "id": "tgs-GbM9SXvL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Model Summary:**\n",
        "\n",
        "The model used Logistic Regression.\n",
        "The number of observations is 68353.\n",
        "The Log-Likelihood (log-likelihood value) is approximately -33219.\n",
        "The model converged successfully (converged: True).\n",
        "Pseudo R-squared is around 0.01841, indicating the proportion of variance explained by the model.\n",
        "\n",
        "### **Coefficient Estimates:**\n",
        "\n",
        "Intercept: -1.0444\n",
        "Subject_Hotness_Score: -0.3706\n",
        "These are the estimated coefficients for the intercept and the 'Subject_Hotness_Score' predictor.\n",
        "\n",
        "### **Statistical Significance:**\n",
        "\n",
        "Both the intercept and 'Subject_Hotness_Score' have associated p-values (P>|z|) less than 0.05, suggesting statistical significance.\n",
        "\n",
        "###**Z observed statistic:**\n",
        "\n",
        "The Z observed statistic for the 'Subject_Hotness_Score' is approximately -33.55, calculated as the coefficient divided by its standard error.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "You can interpret the coefficients as follows:\n",
        "\n",
        "For every one-unit increase in the Subject Hotness Score, the log-odds of the Email Status being 'Read' or 'Acknowledged' decreases by approximately 0.3706 units, assuming other variables remain constant"
      ],
      "metadata": {
        "id": "2E-uyhh4SX9V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The statistical test used to obtain the p-values in logistic regression is the Wald test. In logistic regression, each coefficient's significance is evaluated using the Wald statistic, which follows a chi-squared distribution."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In logistic regression, the statistical test used to assess the significance of coefficients (such as the Wald test) is chosen based on the maximum likelihood estimation (MLE) framework, which forms the foundation of logistic regression."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis.\n",
        "\n",
        "\n",
        "**Null Hypothesis (H0):** There is no significant relationship between the time categories (morning, evening, night) when emails are sent and the Email_Status outcomes (ignored, read, acknowledged) by the recipients.\n",
        "\n",
        "\n",
        "**Alternate Hypothesis (H1):** There is a significant relationship between the time categories (morning, evening, night) when emails are sent and the Email_Status outcomes (ignored, read, acknowledged) by the recipients.."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Create a contingency table (cross-tabulation)\n",
        "contingency_table = pd.crosstab(df['Time_Email_sent_Category'], df['Email_Status'])\n",
        "\n",
        "#Manually specify degrees of freedom\n",
        "degrees_of_freedom_threshold = 3\n",
        "\n",
        "# Perform the chi-squared test with specified degrees of freedom\n",
        "chi2, p, _, expected = chi2_contingency(contingency_table, degrees_of_freedom_threshold)\n",
        "\n",
        "\n",
        "# Print the results\n",
        "print(f\"Chi-Squared Statistic: {chi2}\")\n",
        "print(f\"P-value: {p}\")\n",
        "print(f\"Degrees of Freedom: {degrees_of_freedom_threshold}\")\n",
        "print(\"Contingency Table:\")\n",
        "print(contingency_table)"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation:**\n",
        "\n",
        "The p-value obtained from the chi-squared test is 0.911, which is greater than the typical significance level of 0.05. Therefore, at a 5% significance level, there is not enough evidence to reject the null hypothesis.\n",
        "\n",
        "This suggests that based on the provided data, there is no significant association between the time categories of emails sent ('morning,' 'evening,' 'night') and the Email_Status outcomes (ignored, read, acknowledged). The observed distribution of Email_Status across different time categories could likely be due to random chance rather than a meaningful relationship between the time of sending and email engagement."
      ],
      "metadata": {
        "id": "Psscn0dLS8zP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The statistical test used to obtain the p-value in this scenario is the Chi-squared test for independence.\n",
        "\n",
        "The Chi-squared test for independence is employed when you have categorical data and want to assess whether there is a significant association (or independence) between two categorical variables. In this case, the variables under consideration are 'Time_Email_sent_Category' (categorical, representing different times of the day when emails were sent) and 'Email_Status' (categorical, indicating whether the email was ignored, read, or acknowledged)."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Chi-squared test was chosen because it is a widely used statistical method for assessing independence or association between categorical variables, making it suitable for investigating the relationship between the time categories of email sending and the resulting email engagement statuses, as described in the research hypothesis."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis.\n",
        "\n",
        "**Null Hypothesis (H0):**\n",
        "\n",
        "\"There is no significant association between Email_Type or Email_Campaign_Type categories and Email_Status.\"\n",
        "\n",
        "**Alternative Hypothesis (H1):**\n",
        "\n",
        "\"There is a significant association between Email_Type or Email_Campaign_Type categories and Email_Status.\""
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Contingency table of frequencies\n",
        "contingency_table = pd.crosstab(df['Email_Campaign_Type'], df['Email_Status'])\n",
        "\n",
        "# Chi-squared test of independence\n",
        "chi2, p_val, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "print(f\"Chi-squared statistic: {chi2}\")\n",
        "print(f\"P-value: {p_val}\\n\")\n",
        "\n",
        "print(f\"Contigency Table:\\n \\n{contingency_table}\")"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation:**\n",
        "\n",
        "Given the very low p-value (<< 0.05), we reject the null hypothesis, indicating a significant association between 'Email_Campaign_Type' and 'Email_Status'. This implies that the type of email campaign significantly influences the email status outcomes.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tEBOygDSTct-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The statistical test used to obtain the p-value in this scenario is the Chi-squared test of independence.\n",
        "\n",
        "The Chi-squared test of independence is employed when dealing with categorical data from two or more groups and aims to determine whether there is a significant association between the categorical variables. It evaluates whether the observed frequency distribution differs significantly from the expected frequency distribution under the assumption of independence between the variables."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Chi-squared test of independence is specifically designed for analyzing the association between categorical variables. It helps in assessing whether there is a significant relationship or dependence between two categorical variables. It examines whether the observed frequencies in a contingency table significantly differ from the frequencies that would be expected if the variables were independent of each other.\n",
        "\n",
        "Therefore, the Chi-squared test was chosen as it is a widely used statistical test for examining associations between categorical variables and was suitable for determining whether the 'Email_Campaign_Type' significantly affects the distribution of 'Email_Status' categories."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Deleting the Intercept and Email_Status_Binary columns as it is not needed for further analysis"
      ],
      "metadata": {
        "id": "PMaErkbUAbMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping Intercept column\n",
        "df.drop(columns=['Intercept'], inplace=True)"
      ],
      "metadata": {
        "id": "TCoF_6M0AZ8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping Email_Status_Binary column\n",
        "df.drop(columns=['Email_Status_Binary'], inplace=True)"
      ],
      "metadata": {
        "id": "PUdruQe_AaKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above Data we realise that 4 features have null values.\n",
        "\n",
        " Customer_Location\n",
        "\n",
        " Total_past_communications\n",
        "\n",
        " Total_Links\n",
        "\n",
        " Total_Images"
      ],
      "metadata": {
        "id": "oWtbaaf63ujm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Customer Location feature:**\n",
        "We have already seen in our missing values analysis that the Customer_Location feature has the most number of missing values (11595 missing values).\n",
        "\n",
        " Also, in categorical data analysis, after plotting the frequency graph of different values of Customer_location with respect to the Email_status category we found that the percentage ratio of Email being Ignored, Read or Acknowledged is the same irrespective of the location.\n",
        "\n",
        "-The Customer_Location feature does not affect Email_Status\n",
        "\n",
        "-We can drop Customer_Locaton feature"
      ],
      "metadata": {
        "id": "A-CVIkke4Bu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar chart for Customer_location vs. Email_Status\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='Customer_Location', hue='Email_Status', data=df, palette=pastel_palette)\n",
        "plt.title('Customer_location vs. Email Status')\n",
        "plt.xlabel('Customer_location')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(title='Email Status')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fyjoHEYW03vp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "after plotting the frequency graph of different values of Customer_location with respect to the Email_status category we found that the percentage ratio of Email being Ignored, Read or Acknowledged is the same irrespective of the location.\n",
        "\n",
        "Hence we will Drop the column"
      ],
      "metadata": {
        "id": "5VmM-wy13u9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping Customer_Location column\n",
        "df.drop(columns=['Customer_Location'], inplace=True)"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute missing values for Total Past Communications with mean\n",
        "df['Total_Past_Communications'].fillna(df['Total_Past_Communications'].mean(), inplace = True)\n"
      ],
      "metadata": {
        "id": "Gz3FfAJM4vBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filling up the Total Links Column\n",
        "df['Total_Links'].fillna(df['Total_Links'].mode()[0], inplace = True)\n"
      ],
      "metadata": {
        "id": "Oxe4K_uU4vE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filling up the Total Images Column\n",
        "df['Total_Images'].fillna(df['Total_Images'].mode()[0], inplace = True)"
      ],
      "metadata": {
        "id": "bv40W8QA45av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping Email_Id column as it is not needed for ML model\n",
        "df.drop(columns=['Email_ID'], inplace=True)"
      ],
      "metadata": {
        "id": "Z-fcbKvm6xoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean Imputation for 'Total_Past_Communications':\n",
        "Used mean imputation to fill missing values.\n",
        "Imputed with the mean of existing values to maintain the overall distribution and minimize the impact of outliers.\n",
        "\n",
        "Mode Imputation for 'Total_Links' and 'Total_Images':\n",
        "Used mode imputation to fill missing values.\n",
        "Imputed with the mode (most frequent value) to capture the central tendency and maintain the categorical nature of the features.\n",
        "\n",
        "Dropping 'Customer_Location' and 'Email_ID' columns:\n",
        "Removed 'Customer_Location' as the analysis indicated it didn't significantly impact email status.\n",
        "Removed 'Email_ID' as it was deemed unnecessary for the ML model.\n",
        "\n",
        "These techniques were chosen based on the nature of the data and the goal of maintaining representativeness in imputed values while removing irrelevant features for the machine learning model."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "# Perform one-hot encoding using get_dummies function in pandas\n",
        "df= pd.get_dummies(df, columns=['Email_Type', 'Email_Source_Type', 'Email_Campaign_Type', 'Time_Email_sent_Category'])\n",
        "\n"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "-bz6xeCLN4Kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will **Delete** the following columns due to the Collinearity:\n",
        "\n",
        "**'Email_Type_2'**\n",
        "\n",
        "**'Email_Source_Type_2'**,\n",
        "\n",
        "**'Email_Campaign_Type_3'**,\n",
        "\n",
        "**'Time_Email_sent_Category_3'**"
      ],
      "metadata": {
        "id": "j-jRRZVd-qRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping multiple columns using subset parameter\n",
        "columns_to_drop = ['Email_Type_2', 'Email_Source_Type_2', 'Email_Campaign_Type_3', 'Time_Email_sent_Category_3']\n",
        "\n",
        "df.drop(columns=df.columns[df.columns.isin(columns_to_drop)], inplace=True)"
      ],
      "metadata": {
        "id": "N0yjK7SP-pCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "zUFZ4g_bBRnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One-Hot Encoding:**\n",
        "\n",
        "Applied one-hot encoding using the get_dummies function in pandas for categorical columns: 'Email_Type', 'Email_Source_Type', 'Email_Campaign_Type', and 'Time_Email_sent_Category'.\n",
        "One-hot encoding was chosen to convert categorical variables into a binary matrix representation, allowing the model to interpret and learn from these categorical features.\n",
        "\n",
        "**Column Dropping for Multicollinearity:**\n",
        "\n",
        "Dropped certain one-hot encoded columns to address multicollinearity issues.\n",
        "Removed 'Email_Type_2', 'Email_Source_Type_2', 'Email_Campaign_Type_3', and 'Time_Email_sent_Category_3' to avoid redundancy and linear dependence among features.\n",
        "\n",
        "These techniques were employed to prepare the categorical features for machine learning models. One-hot encoding facilitates the incorporation of categorical data into the model, while column dropping addresses issues related to multicollinearity, ensuring a more stable and effective model."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the  'Total_Images' column\n",
        "df.drop('Total_Images', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "pOLsO6IU5Ngz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see from the correlation matrix that the Total_Images and Total_Links are exceeding the 0.7 correlation Threshold\n",
        "\n",
        "We have removed 'Total_Images' column\n",
        "\n"
      ],
      "metadata": {
        "id": "1feFYj775Roz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The decision to remove the 'Total_Images' column due to high correlation with 'Total_Links' indicates an effort to mitigate multicollinearity, which can be detrimental to certain machine learning models.\n",
        "\n",
        "Regarding data transformation, while it's not explicitly mentioned in the provided information, one common technique to address high multicollinearity is feature scaling. This involves scaling the features to a similar range. Common methods include Min-Max scaling or Z-score normalization."
      ],
      "metadata": {
        "id": "54s3NYds5d1n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "-kkfvKMEmjii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "IYYcXvPCCerb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "\n",
        "# 'X' contains the predictor variables\n",
        "X = df.drop(columns=['Email_Status'], axis=1)\n",
        "\n",
        "# Calculate VIF for each predictor variable\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Feature\"] = X.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "print(vif_data)"
      ],
      "metadata": {
        "id": "36bKsqWUDZR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "WT3X3OxYPXkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define an impurity function, in this case, for 'entropy'\n",
        "def compute_impurity(data):\n",
        "    # Calculate unique classes and their frequencies manually\n",
        "    unique_classes = list(set(data))\n",
        "    counts = [list(data).count(cls) for cls in unique_classes]\n",
        "\n",
        "    # Calculate probabilities for each class\n",
        "    probabilities = np.array(counts) / len(data)\n",
        "\n",
        "    # Calculate entropy\n",
        "    entropy = -np.sum(probabilities * np.log2(probabilities))\n",
        "\n",
        "    return entropy\n",
        "\n",
        "def comp_feature_information_gain(target, descriptive_feature, data):\n",
        "    # Calculate the entropy of the entire target variable (before splitting)\n",
        "    target_entropy = compute_impurity(data[target])\n",
        "\n",
        "    # Initialize lists to store entropy and weights for each level of the descriptive feature\n",
        "    entropy_list = []\n",
        "    weight_list = []\n",
        "\n",
        "    # Loop over each level of the descriptive feature\n",
        "    for level in set(data[descriptive_feature]):\n",
        "        # Partition the dataset with respect to the current level\n",
        "        df_feature_level = data[data[descriptive_feature] == level]\n",
        "\n",
        "        # Compute the entropy of the partition\n",
        "        entropy_level = compute_impurity(df_feature_level[target])\n",
        "\n",
        "        # Append the computed entropy to the entropy_list\n",
        "        entropy_list.append(round(entropy_level, 3))\n",
        "\n",
        "        # Calculate the weight of the level's partition\n",
        "        weight_level = len(df_feature_level) / len(data)\n",
        "        weight_list.append(round(weight_level, 3))\n",
        "\n",
        "    # Compute the remaining impurity of the feature after splitting\n",
        "    feature_remaining_impurity = np.sum(np.array(entropy_list) * np.array(weight_list))\n",
        "\n",
        "    # Calculate the Information Gain\n",
        "    information_gain = target_entropy - feature_remaining_impurity\n",
        "\n",
        "    return information_gain\n",
        "\n",
        "# Assuming df is your DataFrame\n",
        "X = df.drop(columns=['Email_Status'])\n",
        "\n",
        "# Loop through each feature in X and calculate information gain separately\n",
        "information_gains = {}\n",
        "for feature in X:\n",
        "    info_gain = comp_feature_information_gain('Email_Status', feature, df)\n",
        "    information_gains[feature] = info_gain\n",
        "\n",
        "# Plotting the bar chart for all features\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(information_gains.keys(), information_gains.values(), color='skyblue')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Information Gain')\n",
        "plt.title('Information Gain for Each Feature')\n",
        "plt.xticks(rotation=90)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Adding annotations to display information values on each bar\n",
        "for feature, info_gain in information_gains.items():\n",
        "    plt.text(feature, info_gain + 0.01, round(info_gain, 2), ha='center', va='bottom', fontsize=10, color='black')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XQDgRuguF-Xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see from the Bar chart the **'Time_Email_sent_Category_1'**, and\n",
        "\n",
        "**'Time_Email_sent_Category_2'** has negative  *information gain score we will drop those columns"
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming df is your DataFrame\n",
        "columns_to_drop = ['Time_Email_sent_Category_1', 'Time_Email_sent_Category_2']\n",
        "\n",
        "# Drop the specified columns\n",
        "df.drop(columns=columns_to_drop, inplace=True)\n"
      ],
      "metadata": {
        "id": "vkZCK3EWlpDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VIF:** It assesses the multicollinearity among predictor variables. Features with high VIF values (greater than a threshold, often 5 or 10) are considered to be highly correlated with other features and might be candidates for removal to enhance model stability.\n",
        "\n",
        "Information Gain: It is a measure from information theory used for feature selection in decision trees. Features with higher information gain are considered more informative for predicting the target variable.\n",
        "\n",
        "These methods are employed to address issues such as multicollinearity and to prioritize features based on their ability to provide information for predicting the target variable."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Features with Low VIF:**\n",
        "\n",
        "'Subject_Hotness_Score', 'Total_Past_Communications', 'Word_Count', 'Total_Links', 'Email_Type_1', 'Email_Source_Type_1', 'Email_Campaign_Type_1' have VIF values below 6, indicating low multicollinearity.\n",
        "\n",
        "**Features with Positive Information Gain:**\n",
        "\n",
        "'Subject_Hotness_Score', 'Total_Past_Communications', 'Word_Count', 'Total_Links', 'Email_Type_1', 'Email_Source_Type_1', 'Email_Campaign_Type_1', 'Email_Campaign_Type_2' have positive information gain values, suggesting their importance in predicting the 'Email_Status' target variable.\n",
        "\n",
        "Considering these aspects, the mentioned features are likely considered important for predicting the target variable while addressing multicollinearity issues. The removal of 'Time_Email_sent_Category_1' and 'Time_Email_sent_Category_2' is based on their negative information gain scores, indicating that they may not contribute positively to predicting the target variable."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Outlier detection\n",
        "\n",
        "#specified columns\n",
        "columns_to_plot = ['Subject_Hotness_Score', 'Total_Past_Communications', 'Word_Count', 'Total_Links']\n",
        "\n",
        "# Create boxplots for each specified column\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i, column in enumerate(columns_to_plot, 1):\n",
        "    plt.subplot(2, 2, i)\n",
        "    sns.boxplot(y=df[column], color='skyblue')\n",
        "    plt.title(f' {column}')\n",
        "    plt.ylabel(column)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "l2c9E6PnmWgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Except for the Word_Count column all other numeric columns have outliers.\n",
        "### Since our dependent variable is highly imbalanced so before dropping outliers we should check that it will not delete more than 5% of the minority class which is Email_Status =1,2,3."
      ],
      "metadata": {
        "id": "nDb0X3Xhw7UF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming df is your DataFrame containing the specified columns and the 'Email_Status' column\n",
        "# Ensure 'Email_Status' column name matches the actual column name in your DataFrame\n",
        "\n",
        "# Columns to analyze for outliers\n",
        "columns_to_check = ['Subject_Hotness_Score', 'Total_Past_Communications', 'Total_Links']\n",
        "\n",
        "# Check if the column 'Email_Status' exists in your DataFrame\n",
        "if 'Email_Status' in df.columns:\n",
        "    outliers_percentage = {}\n",
        "\n",
        "    # Calculate outliers based on IQR for each column with respect to 'Email_Status'\n",
        "    for column in columns_to_check:\n",
        "        outliers_percentage[column] = {}\n",
        "\n",
        "        # Group by 'Email_Status' and detect outliers using IQR method\n",
        "        for status, group in df.groupby('Email_Status'):\n",
        "            Q1 = group[column].quantile(0.25)\n",
        "            Q3 = group[column].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "            # Calculate percentage of outliers for each 'Email_Status'\n",
        "            outliers_count = ((group[column] < lower_bound) | (group[column] > upper_bound)).sum()\n",
        "            total_instances = len(group[column])\n",
        "            outliers_percentage[column][status] = (outliers_count / total_instances) * 100\n",
        "\n",
        "    # Create a bar chart to visualize the percentage of outliers for each column\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for i, column in enumerate(columns_to_check, 1):\n",
        "        plt.subplot(2, 2, i)\n",
        "        bars = plt.bar(outliers_percentage[column].keys(), outliers_percentage[column].values())\n",
        "        plt.title(f'{column} vs Email_Status')\n",
        "        plt.xlabel('Email_Status')\n",
        "        plt.ylabel('Percentage of Outliers')\n",
        "\n",
        "        # Adding annotations (percentage values) on top of each bar\n",
        "        for rect in bars:\n",
        "            height = rect.get_height()\n",
        "            plt.annotate(f'{height:.2f}%',\n",
        "                         xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                         xytext=(0, 3),  # 3 points vertical offset\n",
        "                         textcoords=\"offset points\",\n",
        "                         ha='center', va='bottom')\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Column 'Email_Status' not found in the DataFrame.\")\n"
      ],
      "metadata": {
        "id": "7fYSFsn8nSaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see 5% of data was being removed from minority class.\n",
        "\n",
        "We are not going to remove outliers"
      ],
      "metadata": {
        "id": "b4o8o_PJyClG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outlier Treatment Techniques Used:\n",
        "\n",
        "**Visualization using Boxplots:**\n",
        "\n",
        "Used boxplots to visually inspect the distribution and identify potential outliers in the specified numeric columns ('Subject_Hotness_Score', 'Total_Past_Communications', 'Word_Count', 'Total_Links').\n",
        "Boxplots are effective for identifying the presence of outliers and understanding the spread of data.\n",
        "\n",
        "**Outlier Detection using IQR:**\n",
        "\n",
        "Calculated outliers based on the Interquartile Range (IQR) method for each specified column with respect to the 'Email_Status' groups.\n",
        "Determined upper and lower bounds for outliers and assessed the percentage of outliers for each 'Email_Status' group.\n",
        "\n",
        "**Decision not to Remove Outliers:**\n",
        "\n",
        "Based on the observation that removing outliers would result in the deletion of more than 5% of the minority class (Email_Status = 1, 2, 3), a decision was made not to perform outlier removal.\n",
        "Retaining outliers might be crucial in scenarios where they represent important and legitimate variations in the data, especially when dealing with imbalanced classes.\n",
        "\n",
        "The decision not to remove outliers in this case is informed by the need to preserve the minority class instances and maintain a more representative dataset for the imbalanced classification task.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mueLHk-QwsHD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Assuming df is your DataFrame containing the specified columns\n",
        "\n",
        "# Select columns for normalization\n",
        "columns_to_normalize = ['Subject_Hotness_Score', 'Total_Past_Communications', 'Word_Count', 'Total_Links']\n",
        "\n",
        "# Create a MinMaxScaler object\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Normalize the selected columns using MinMaxScaler\n",
        "df_normalized = df.copy()  # Create a copy of the DataFrame\n",
        "df_normalized[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])\n",
        "\n"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_normalized"
      ],
      "metadata": {
        "id": "L5nKMCNc0HDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Min-Max Scaling:\n",
        "\n",
        "**Methodology:**\n",
        "\n",
        "Min-Max Scaling, also known as normalization, transforms the data into a specific range, usually between 0 and 1.\n",
        "It scales the values based on the minimum and maximum values of the feature, bringing them into a uniform range.\n",
        "\n",
        "**Why Min-Max Scaling?**\n",
        "\n",
        "Min-Max Scaling is particularly useful when features have different ranges or units, and you want to bring them to a standardized scale.\n",
        "It preserves the relative relationships between values, maintaining the distribution of the data.\n",
        "Many machine learning algorithms, especially distance-based ones (e.g., k-Nearest Neighbors), perform better when features are on a similar scale.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NxVfXSZb0-rc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming your dataset is stored in a DataFrame named 'data'\n",
        "# X contains the features, and y contains the target variable\n",
        "X = df.drop(columns=['Email_Status'])\n",
        "y = df['Email_Status']\n",
        "\n",
        "# Splitting the data using stratified sampling\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stratified Sampling:**\n",
        "\n",
        "The stratify=y parameter is used, which ensures that the class distribution in the target variable 'Email_Status' is maintained in both the training and testing sets.\n",
        "This is crucial, especially when dealing with imbalanced classes, to prevent a disproportionate representation of classes in either the training or testing set.\n",
        "\n",
        "**Common Practice:**\n",
        "\n",
        "An 80-20 or 70-30 split is a common practice in machine learning.\n",
        "The majority of data is allocated to training to allow the model to learn patterns and relationships in the data.\n",
        "A smaller portion is allocated to testing to evaluate the model's performance on unseen data.\n",
        "\n",
        "Random State:\n",
        "\n",
        "random_state=42 is used to ensure reproducibility. The same random state will result in the same split when the code is run multiple times.\n",
        "\n",
        "The 80-20 split is a reasonable choice, providing a sufficient amount of data for training while reserving a reasonable portion for testing. The use of stratified sampling is particularly important to address class imbalance, ensuring that both sets are representative of the overall class distribution."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the count of each class in the 'Email_Status' column\n",
        "class_counts = df['Email_Status'].value_counts()\n",
        "\n",
        "# Create a bar chart to visualize the count of each class\n",
        "plt.figure(figsize=(8, 6))\n",
        "bars = plt.bar(class_counts.index.astype(str), class_counts.values, color='skyblue')\n",
        "\n",
        "# Adding annotations (count values) on top of each bar\n",
        "for rect in bars:\n",
        "    height = rect.get_height()\n",
        "    plt.annotate(f'{height}',\n",
        "                 xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                 xytext=(0, 3),  # 3 points vertical offset\n",
        "                 textcoords=\"offset points\",\n",
        "                 ha='center', va='bottom')\n",
        "\n",
        "plt.xlabel('Email Status')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Count of Each Class in Email Status')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7QuLNVRm1wa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, based on the provided bar chart and class counts, the dataset is imbalanced. Here's why:\n",
        "\n",
        "**Class Distribution:**\n",
        "\n",
        "Class 0 has a significantly larger count (54941) compared to Class 1 (11039) and Class 2 (2373).\n",
        "Class 0 dominates the dataset in terms of the number of instances, creating an imbalance in class distribution.\n",
        "\n",
        "**Visual Imbalance:**\n",
        "\n",
        "The bar chart visually highlights the disparity in counts among the different classes.\n",
        "Imbalanced datasets often lead to challenges in training machine learning models, especially when the minority class (in this case, Class 1 and Class 2) has fewer instances.\n",
        "\n",
        "**Impact on Model Training:**\n",
        "\n",
        "Imbalanced datasets can affect the learning process of machine learning models, potentially leading to biased predictions favoring the majority class.\n",
        "Models may become overly sensitive to the majority class and may struggle to accurately predict instances from the minority class.\n",
        "\n"
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Separate features and target variable\n",
        "X = X_train\n",
        "y = y_train\n",
        "\n",
        "# Display class distribution before balancing\n",
        "print(\"Before balancing:\")\n",
        "before_counts = Counter(y)\n",
        "print(before_counts)\n",
        "\n",
        "# Visualizing class distribution before balancing\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(before_counts.keys(), before_counts.values(), color='skyblue')\n",
        "plt.title('Class Distribution Before Balancing')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(list(before_counts.keys()))\n",
        "plt.show()\n",
        "\n",
        "# Apply SMOTE for over-sampling\n",
        "smote = SMOTE(random_state=42)\n",
        "X_SMOTE_resampled, y_SMOTE_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Display class distribution after balancing\n",
        "print(\"\\nAfter balancing:\")\n",
        "after_counts = Counter(y_SMOTE_resampled)\n",
        "print(after_counts)\n",
        "\n",
        "# Visualizing class distribution after balancing\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(after_counts.keys(), after_counts.values(),  color='skyblue')\n",
        "plt.title('Class Distribution After Balancing')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(list(after_counts.keys()))\n",
        "plt.show()\n",
        "\n",
        "# Now you can use X_SMOTE_resampled and y_SMOTE_resampled for model training\n"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Technique Used:\n",
        "\n",
        "SMOTE (Synthetic Minority Over-sampling Technique):\n",
        "\n",
        "**Methodology:**\n",
        "SMOTE is an oversampling technique designed to address imbalanced datasets by generating synthetic examples for the minority class.\n",
        "It works by creating synthetic instances along the line segments connecting existing minority class instances.\n",
        "This process helps balance the class distribution by introducing synthetic examples without duplicating existing instances.\n",
        "\n",
        "**Why SMOTE:**\n",
        "Imbalanced datasets can lead machine learning models to be biased toward the majority class, affecting their ability to generalize to minority classes.\n",
        "SMOTE is effective in overcoming this issue by increasing the representation of the minority class, thus improving model performance on minority class instances.\n",
        "\n",
        "**Before Balancing:**\n",
        "The class distribution before balancing was imbalanced, with Class 0 having significantly more instances than Class 1 and Class 2.\n",
        "\n",
        "**After Balancing:**\n",
        "After applying SMOTE, the class distribution was balanced, with each class having an equal number of instances (43953).\n",
        "\n",
        "**Conclusion:**\n",
        "\n",
        "The choice of SMOTE in this scenario is justified when dealing with imbalanced datasets, as it helps create a more representative training set by introducing synthetic instances of the minority class. This balanced dataset is then suitable for training machine learning models that can make more accurate predictions on all classes."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = X_SMOTE_resampled, y_SMOTE_resampled"
      ],
      "metadata": {
        "id": "GRCW7XBz3cPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1\n",
        "\n",
        "## LogisticRegression"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_recall_curve, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "log_reg = LogisticRegression()\n",
        "\n",
        "# Train the model on the training data\n",
        "log_reg.fit(X_train, y_train)  # Replace X_SMOTE_resampled with X_train and y_SMOTE_resampled with y_train\n",
        "\n",
        "# Predict on the training set\n",
        "train_predictions = log_reg.predict(X_train)  # Replace X_SMOTE_resampled with X_train\n",
        "\n",
        "# Predict on the test set\n",
        "test_predictions = log_reg.predict(X_test)\n",
        "\n",
        "# Calculate accuracy scores\n",
        "train_accuracy = accuracy_score(y_train, train_predictions)  # Replace y_SMOTE_resampled with y_train\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "\n",
        "# Calculate F1 score, precision, and recall for train and test sets\n",
        "model1_train_f1 = f1_score(y_train, train_predictions, average='weighted')  # Replace y_SMOTE_resampled with y_train\n",
        "model1_test_f1 = f1_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "train_precision = precision_score(y_train, train_predictions, average='weighted')  # Replace y_SMOTE_resampled with y_train\n",
        "test_precision = precision_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "train_recall = recall_score(y_train, train_predictions, average='weighted')  # Replace y_SMOTE_resampled with y_train\n",
        "test_recall = recall_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "# Print the accuracy, F1 score, precision, and recall scores\n",
        "\n",
        "print(\"Training F1 Score:\", model1_train_f1)\n",
        "print(\"Testing F1 Score:\", model1_test_f1)\n",
        "\n",
        "# Visualize Precision-Recall curve for both train and test sets\n",
        "train_precision, train_recall, _ = precision_recall_curve(y_train, log_reg.predict_proba(X_train)[:, 1], pos_label=log_reg.classes_[1])  # Replace y_SMOTE_resampled with y_train and X_SMOTE_resampled with X_train\n",
        "test_precision, test_recall, _ = precision_recall_curve(y_test, log_reg.predict_proba(X_test)[:, 1], pos_label=log_reg.classes_[1])\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(train_recall, train_precision, label='Train Precision-Recall curve')\n",
        "plt.plot(test_recall, test_precision, label='Test Precision-Recall curve')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Calculate confusion matrix for test set\n",
        "cm = confusion_matrix(y_test, test_predictions)\n",
        "\n",
        "# Plot confusion matrix as a heatmap\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML Model Used: Logistic Regression\n",
        "\n",
        "**Performance Evaluation Metric Scores:**\n",
        "\n",
        "**Training F1 Score: 0.526**\n",
        "\n",
        "The F1 score on the training set is 0.526, indicating a balance between precision and recall. F1 score is suitable for imbalanced datasets, providing a harmonic mean of precision and recall.\n",
        "\n",
        "**Testing F1 Score: 0.655**\n",
        "\n",
        "The F1 score on the testing set is 0.655, suggesting reasonable generalization performance on unseen data.\n",
        "\n",
        "**Precision-Recall Curve:**\n",
        "\n",
        "The Precision-Recall curve visualizes the trade-off between precision and recall at different probability thresholds.\n",
        "Both the training and testing Precision-Recall curves are shown in the plot.\n",
        "The curves illustrate the model's ability to make precise predictions (high precision) while maintaining a high recall rate.\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "The model displays high performance on the training set, as indicated by a Training F1 Score of 0.803. However, on the test set, the F1 score drops to 0.655, suggesting a potential issue of overfitting. The Precision-Recall curve illustrates a balance between precision and recall during training, but this balance does not fully translate to the test set, indicating challenges in generalization. The confusion matrix further emphasizes discrepancies, revealing areas where the model excels on the training data but faces difficulties when applied to unseen test instances. Addressing overfitting might involve refining the model complexity, considering regularization techniques, or exploring additional features to enhance generalization capabilities.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Note:**\n",
        "\n",
        "The choice of evaluation metrics depends on the specific goals of the project. F1 score is a suitable metric when there is an imbalance between classes, and both precision and recall are crucial. It's important to consider the context of the problem and the consequences of false positives and false negatives."
      ],
      "metadata": {
        "id": "JaEsixAn3XLl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2\n",
        "\n",
        "##RandomForestClassifier"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_recall_curve, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize the Random Forest Classifier with bagging method\n",
        "random_forest_bagging = RandomForestClassifier(n_estimators=100, random_state=42, bootstrap=True)  # Enable bagging\n",
        "\n",
        "# Train the model on the training data\n",
        "random_forest_bagging.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the training set\n",
        "train_predictions = random_forest_bagging.predict(X_train)\n",
        "\n",
        "# Predict on the test set\n",
        "test_predictions = random_forest_bagging.predict(X_test)\n",
        "\n",
        "# Calculate accuracy scores\n",
        "train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "\n",
        "# Calculate F1 score, precision, and recall for train and test sets\n",
        "model2_train_f1 = f1_score(y_train, train_predictions, average='weighted')\n",
        "model2_test_f1 = f1_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "train_precision = precision_score(y_train, train_predictions, average='weighted')\n",
        "test_precision = precision_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "train_recall = recall_score(y_train, train_predictions, average='weighted')\n",
        "test_recall = recall_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "# Print the accuracy, F1 score, precision, and recall scores\n",
        "print(\"Training F1 Score:\", model2_train_f1)\n",
        "print(\"Testing F1 Score:\", model2_test_f1)\n",
        "\n",
        "\n",
        "# Example: Compute and plot precision-recall curves for each class separately (One-vs-Rest)\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Iterate over each class separately\n",
        "for class_label in random_forest_bagging.classes_:\n",
        "    class_indices = (y_test == class_label)\n",
        "    y_test_binary = class_indices.astype(int)\n",
        "    y_score = random_forest_bagging.predict_proba(X_test)[:, class_label]\n",
        "\n",
        "    # Compute precision-recall curve for each class\n",
        "    precision, recall, _ = precision_recall_curve(y_test_binary, y_score)\n",
        "    plt.plot(recall, precision, label=f'Class {class_label}')\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve for each class (One-vs-Rest)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Calculate confusion matrix for test set\n",
        "cm = confusion_matrix(y_test, test_predictions)\n",
        "\n",
        "# Plot confusion matrix as a heatmap\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "jOSRi3F733E8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ML Model Used: Random Forest Classifier with Bagging**\n",
        "\n",
        "**Performance Evaluation Metric Scores**\n",
        "\n",
        "**Training F1 Score: 0.998**\n",
        "\n",
        "The F1 score on the training set is exceptionally high (close to 1.0), indicating that the Random Forest Classifier with bagging has effectively learned the patterns in the training data.\n",
        "\n",
        "**Testing F1 Score: 0.756**\n",
        "\n",
        "The F1 score on the testing set is 0.756, which is a good performance metric considering the context of your problem.\n",
        "\n",
        "**Precision-Recall Curve for Each Class (One-vs-Rest):**\n",
        "\n",
        "The precision-recall curves for each class are plotted separately in the chart. This visualization helps assess the trade-off between precision and recall for different probability thresholds.\n",
        "It is evident that the model performs well for each class, achieving high precision and recall values.\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "The Random Forest Classifier with bagging exhibits outstanding performance on the training set, achieving near-perfect F1 scores. This suggests that the model has successfully learned the patterns present in the training data. Importantly, on the test set, the model maintains a high F1 score of 0.756, indicating robust generalization to unseen data. The precision-recall curves for each class underscore the model's ability to make accurate predictions across diverse classes. The confusion matrix serves as additional validation, highlighting the model's effectiveness in correctly classifying instances. Overall, the Random Forest Classifier with bagging proves to be a powerful and reliable model for this classification task.\n",
        "\n",
        "**Considerations:**\n",
        "\n",
        "The high F1 score on the training set raises the possibility of overfitting. It's crucial to monitor and fine-tune the model to ensure it generalizes well to new, unseen data.\n",
        "Random Forest with bagging is known for its robustness and ability to handle complex relationships in data.\n"
      ],
      "metadata": {
        "id": "3FYIw37U4AFu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML - Model 3\n",
        "\n",
        "## KNN"
      ],
      "metadata": {
        "id": "7jeK53_J6BkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Scale the features for both train and test sets\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define the KNN classifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors (K) as needed\n",
        "\n",
        "# Train the KNN model\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Calculate F1 score for train set\n",
        "train_predictions = knn.predict(X_train_scaled)\n",
        "model3_train_f1 = f1_score(y_train, train_predictions, average='weighted')\n",
        "\n",
        "# Calculate F1 score for test set\n",
        "test_predictions = knn.predict(X_test_scaled)\n",
        "model3_test_f1 = f1_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "\n",
        "# Output F1 scores\n",
        "print(\"Train F1 Score:\", model3_train_f1)\n",
        "print(\"Test F1 Score:\", model3_test_f1)\n",
        "\n",
        "\n",
        "# Calculate precision-recall curves for each class\n",
        "n_classes = len(set(y_test))  # Number of classes\n",
        "precision = dict()\n",
        "recall = dict()\n",
        "area = dict()\n",
        "\n",
        "for i in range(n_classes):\n",
        "    y_test_binary = (y_test == i)  # Convert to binary classification for each class\n",
        "    probs = knn.predict_proba(X_test_scaled)\n",
        "    precision[i], recall[i], _ = precision_recall_curve(y_test_binary, probs[:, i])\n",
        "    area[i] = auc(recall[i], precision[i])\n",
        "\n",
        "# Plot precision-recall curves for each class\n",
        "plt.figure(figsize=(8, 6))\n",
        "for i in range(n_classes):\n",
        "    plt.plot(recall[i], precision[i], label=f'Class {i} (area = {area[i]:.2f})')\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curves for KNN Classifier (Multiclass)')\n",
        "plt.legend(loc='lower left')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Calculate confusion matrix for test set\n",
        "cm = confusion_matrix(y_test, test_predictions)\n",
        "\n",
        "# Plot confusion matrix as a heatmap\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "x7-A_6Dc6FqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "0VNU4PEL4xKT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML Model Used: K-Nearest Neighbors (KNN) Classifier\n",
        "\n",
        "Performance Evaluation Metric Scores:\n",
        "\n",
        "**Training F1 Score: 0.847**\n",
        "\n",
        "The F1 score on the training set is 0.847, indicating that the KNN model has learned well from the training data and achieved a good balance between precision and recall.\n",
        "\n",
        "**Testing F1 Score: 0.696**\n",
        "\n",
        "The F1 score on the testing set is 0.696, suggesting that the model generalizes reasonably well to new, unseen data.\n",
        "\n",
        "**Precision-Recall Curves for Each Class:**\n",
        "\n",
        "Precision-recall curves are plotted separately for each class in the multiclass classification problem.\n",
        "The area under each precision-recall curve is calculated (AUC) to quantify the classifier's ability to discriminate between classes.\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "The KNN model showcases strong performance on both the training and testing sets, as indicated by the F1 scores. However, a notable discrepancy between the training and testing F1 scores suggests potential overfitting on the training data. The precision-recall curves for each class continue to illustrate the model's proficiency in making accurate predictions across different classes, with AUC values providing a quantitative measure of performance. Despite the overfitting concern, the confusion matrix remains a valuable tool, offering insights into the model's classification performance on the test set and highlighting specific areas where the model excels or may require further\n",
        "\n",
        "**Considerations:**\n",
        "\n",
        "KNN is sensitive to the scale of features, and in this case, feature scaling using StandardScaler has been applied to ensure uniformity in feature magnitudes.\n",
        "The choice of the number of neighbors (K) may impact the model's performance, and it can be fine-tuned based on cross-validation or other hyperparameter tuning techniques.\n",
        "F1 score is used as the evaluation metric, providing a balanced measure of precision and recall, which is especially important in imbalanced datasets."
      ],
      "metadata": {
        "id": "OzQwzCy144um"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML - Model 4\n",
        "\n",
        "##XGBoost"
      ],
      "metadata": {
        "id": "i0qY_nj_62iV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_recall_curve, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize the XGBoost Classifier\n",
        "xgb_classifier = XGBClassifier(n_estimators=100, random_state=42)  # You can adjust the parameters as needed\n",
        "\n",
        "# Train the model on the training data\n",
        "XGBoost_Model = xgb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the training set\n",
        "train_predictions = xgb_classifier.predict(X_train)\n",
        "\n",
        "# Predict on the test set\n",
        "test_predictions = xgb_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy scores\n",
        "train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "\n",
        "# Calculate F1 score, precision, and recall for train and test sets\n",
        "model4_train_f1 = f1_score(y_train, train_predictions, average='weighted')\n",
        "model4_test_f1 = f1_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "\n",
        "train_precision = precision_score(y_train, train_predictions, average='weighted')\n",
        "test_precision = precision_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "train_recall = recall_score(y_train, train_predictions, average='weighted')\n",
        "test_recall = recall_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "# Print the accuracy, F1 score, precision, and recall scores\n",
        "print(\"Training F1 Score:\", model4_train_f1)\n",
        "print(\"Testing F1 Score:\", model4_test_f1)\n",
        "\n",
        "# Example: Compute and plot precision-recall curves for each class separately (One-vs-Rest)\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Iterate over each class separately\n",
        "for class_label in range(xgb_classifier.n_classes_):\n",
        "    class_indices = (y_test == class_label)\n",
        "    y_test_binary = class_indices.astype(int)\n",
        "    y_score = xgb_classifier.predict_proba(X_test)[:, class_label]\n",
        "\n",
        "    # Compute precision-recall curve for each class\n",
        "    precision, recall, _ = precision_recall_curve(y_test_binary, y_score)\n",
        "    plt.plot(recall, precision, label=f'Class {class_label}')\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve for each class (One-vs-Rest)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DUfgI0-_7APt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "h8kOGjXW5fbV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ML Model Used: XGBoost Classifier**\n",
        "\n",
        "Performance Evaluation Metric Scores:\n",
        "\n",
        "**Training F1 Score: 0.804**\n",
        "\n",
        "The F1 score on the training set is 0.804, indicating that the XGBoost model has learned well from the training data and achieved a good balance between precision and recall.\n",
        "\n",
        "**Testing F1 Score: 0.767**\n",
        "\n",
        "The F1 score on the testing set is 0.767, suggesting that the model generalizes reasonably well to new, unseen data.\n",
        "\n",
        "**Precision-Recall Curves for Each Class:**\n",
        "\n",
        "Precision-recall curves are plotted separately for each class in the one-vs-rest multiclass classification problem.\n",
        "The curves illustrate the trade-off between precision and recall for different probability thresholds.\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "The XGBoost model demonstrates good performance on both the training and testing sets, as evidenced by the F1 scores. Precision-recall curves for each class illustrate the model's ability to make accurate predictions for different classes. The confusion matrix offers insights into the model's classification performance on the test set, highlighting areas where the model excels or may need improvement.\n",
        "\n",
        "However, to provide a more comprehensive evaluation, it would be beneficial to explore additional metrics such as precision, recall, and accuracy. Regular model monitoring and potential adjustments, such as hyperparameter tuning, can further enhance the model's effectiveness over time.\n",
        "\n",
        "**Considerations:**\n",
        "\n",
        "XGBoost is an ensemble learning method that combines the predictions of multiple weak learners (trees) to produce a strong learner. It is known for its robustness and high performance.\n",
        "Hyperparameter tuning can be performed to optimize the model's parameters further.\n",
        "Feature importance analysis can be conducted to understand the contribution of each feature to the model's predictions."
      ],
      "metadata": {
        "id": "PQSi7jo15e-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from xgboost import plot_importance\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Fit your XGBoost model (assuming `model` is your trained XGBoost model)\n",
        "\n",
        "# Plot feature importance\n",
        "plot_importance(XGBoost_Model)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RyTRoApFoX2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hperparameter Tunning\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming you have your X and y defined (features and target variable)\n",
        "\n",
        "# Split the data into training and testing sets using stratify\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Define the XGBoost classifier\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "\n",
        "# Define the parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'learning_rate': [0.1, 0.01, 0.05],\n",
        "    'n_estimators': [100, 200, 300]\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV for hyperparameter tuning\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='f1_macro', verbose=2, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Train the XGBoost model with the best hyperparameters\n",
        "best_xgb_model = xgb.XGBClassifier(**best_params)\n",
        "best_xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_train_pred = best_xgb_model.predict(X_train)\n",
        "y_test_pred = best_xgb_model.predict(X_test)\n",
        "\n",
        "# Calculate F1 scores\n",
        "model4_Hyper_train_f1 = f1_score(y_train, y_train_pred, average='macro')\n",
        "model4_Hyper_test_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "\n",
        "\n",
        "# Confusion matrix for train data\n",
        "train_cm = confusion_matrix(y_train, y_train_pred)\n",
        "\n",
        "# Confusion matrix for test data\n",
        "test_cm = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "# Plot confusion matrix heatmaps\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "sns.heatmap(train_cm, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
        "axes[0].set_title('Confusion Matrix - Train Data')\n",
        "axes[0].set_xlabel('Predicted')\n",
        "axes[0].set_ylabel('Actual')\n",
        "\n",
        "sns.heatmap(test_cm, annot=True, fmt='d', cmap='Blues', ax=axes[1])\n",
        "axes[1].set_title('Confusion Matrix - Test Data')\n",
        "axes[1].set_xlabel('Predicted')\n",
        "axes[1].set_ylabel('Actual')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Train F1 Score: {model4_Hyper_train_f1}\")\n",
        "print(f\"Test F1 Score: {model4_Hyper_test_f1}\")\n"
      ],
      "metadata": {
        "id": "2JkLPDrARCiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "MDFGCF4VAcBy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the provided code, you have used GridSearchCV for hyperparameter optimization. GridSearchCV is a technique that performs an exhaustive search over a specified hyperparameter grid, evaluating the model's performance for each combination of hyperparameters using cross-validation.\n",
        "\n",
        "GridSearchCV is chosen for hyperparameter optimization because it systematically explores the entire search space defined by the hyperparameter grid. It performs cross-validation for each combination of hyperparameters, helping to find the set of hyperparameters that maximizes the specified performance metric, in this case, the F1 macro score.\n",
        "\n",
        "The key advantages of using GridSearchCV include:\n",
        "\n",
        "**Exhaustive Search:** It considers all possible combinations of hyperparameter values within the specified grid.\n",
        "\n",
        "**Cross-Validation:** It incorporates cross-validation to ensure that the model's performance is robust and not sensitive to the specific training/test split.\n",
        "\n",
        "**Optimizing F1 Score:** The choice of using the F1 macro score as the evaluation metric indicates a focus on achieving a balance between precision and recall, especially important when dealing with imbalanced datasets."
      ],
      "metadata": {
        "id": "__ZwfsuyAcB_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "d2WDVQXmAYTT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Before Hyperparameter Tuning (XGBoost without tuning):**\n",
        "\n",
        "Training F1 Score: 0.8037\n",
        "Testing F1 Score: 0.7665\n",
        "\n",
        "**After Hyperparameter Tuning (GridSearchCV for XGBoost):**\n",
        "\n",
        "Training F1 Score: 0.4435\n",
        "Testing F1 Score: 0.4076\n",
        "The F1 scores have decreased after hyperparameter tuning."
      ],
      "metadata": {
        "id": "2rl6cvRZAMvx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML - Model 5\n",
        "\n",
        "## Ensemble Model"
      ],
      "metadata": {
        "id": "ui3SKP047T3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 5 Implementation\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize ensemble classifiers\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "ada = AdaBoostClassifier(random_state=42)\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "# Fit the models\n",
        "rf.fit(X_train, y_train)\n",
        "ada.fit(X_train, y_train)\n",
        "gb.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "rf_pred = rf.predict(X_test)\n",
        "ada_pred = ada.predict(X_test)\n",
        "gb_pred = gb.predict(X_test)\n",
        "\n",
        "# Calculate F1 scores for test set\n",
        "f1_rf_test = f1_score(y_test, rf_pred, average='weighted')\n",
        "f1_ada_test = f1_score(y_test, ada_pred, average='weighted')\n",
        "f1_gb_test = f1_score(y_test, gb_pred, average='weighted')\n",
        "\n",
        "# Make predictions on the train set\n",
        "rf_train_pred = rf.predict(X_train)\n",
        "ada_train_pred = ada.predict(X_train)\n",
        "gb_train_pred = gb.predict(X_train)\n",
        "\n",
        "# Calculate F1 scores for train set\n",
        "f1_rf_train = f1_score(y_train, rf_train_pred, average='weighted')\n",
        "f1_ada_train = f1_score(y_train, ada_train_pred, average='weighted')\n",
        "f1_gb_train = f1_score(y_train, gb_train_pred, average='weighted')\n",
        "\n",
        "# Visualization\n",
        "models = ['Random Forest', 'AdaBoost', 'Gradient Boosting']\n",
        "f1_scores_test = [f1_rf_test, f1_ada_test, f1_gb_test]\n",
        "f1_scores_train = [f1_rf_train, f1_ada_train, f1_gb_train]\n",
        "\n",
        "# Store the F1 scores for Model 3\n",
        "model5_rf_train_f1 = f1_rf_train\n",
        "model5_rf_test_f1 = f1_rf_test\n",
        "\n",
        "model5_ada_train_f1 = f1_ada_train\n",
        "model5_ada_test_f1 = f1_ada_test\n",
        "\n",
        "model5_gb_train_f1 = f1_gb_train\n",
        "model5_gb_test_f1 = f1_gb_test\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.bar(models, f1_scores_test, color='skyblue')\n",
        "plt.xlabel('Ensemble Models')\n",
        "plt.ylabel('Test F1 Score')\n",
        "plt.title('Test F1 Score Comparison of Ensemble Models')\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.bar(models, f1_scores_train, color='lightgreen')\n",
        "plt.xlabel('Ensemble Models')\n",
        "plt.ylabel('Train F1 Score')\n",
        "plt.title('Train F1 Score Comparison of Ensemble Models')\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Test F1 Scores:\")\n",
        "print(\"Random Forest:\", f1_rf_test)\n",
        "print(\"AdaBoost:\", f1_ada_test)\n",
        "print(\"Gradient Boosting:\", f1_gb_test)\n",
        "\n",
        "print(\"\\nTrain F1 Scores:\")\n",
        "print(\"Random Forest:\", f1_rf_train)\n",
        "print(\"AdaBoost:\", f1_ada_train)\n",
        "print(\"Gradient Boosting:\", f1_gb_train)\n"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML Models Used: Random Forest, AdaBoost, Gradient Boosting\n",
        "\n",
        "**Performance Evaluation Metric Scores:**\n",
        "\n",
        "**Test F1 Scores:**\n",
        "\n",
        "Random Forest: 0.762\n",
        "AdaBoost: 0.756\n",
        "Gradient Boosting: 0.764\n",
        "\n",
        "**Train F1 Scores:**\n",
        "\n",
        "Random Forest: 0.995\n",
        "AdaBoost: 0.755\n",
        "Gradient Boosting: 0.766\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "All three ensemble models (Random Forest, AdaBoost, Gradient Boosting) demonstrate good performance on both the training and testing sets, as evidenced by high F1 scores. The F1 scores for the Random Forest model on the training and testing sets are 0.995 and 0.762, respectively. For the AdaBoost model, the F1 scores are 0.755 on the training set and 0.756 on the testing set. Finally, the Gradient Boosting model achieves F1 scores of 0.766 on the training set and 0.764 on the testing set.\n",
        "\n",
        "The precision-recall curves for each class illustrate the models' ability to make accurate predictions across different classes, and the confusion matrix provides additional insights into their classification performance on the test set. These ensemble models showcase strong generalization capabilities and can be considered for deployment based on their robust performance.\n",
        "\n",
        "**Random Forest:**\n",
        "\n",
        "Train F1 Score: 0.995\n",
        "Test F1 Score: 0.762\n",
        "The Random Forest model achieves near-perfect F1 scores on the training set and a commendable F1 score on the test set, indicating strong generalization.\n",
        "\n",
        "**AdaBoost:**\n",
        "\n",
        "Train F1 Score: 0.755\n",
        "Test F1 Score: 0.756\n",
        "AdaBoost shows balanced performance on the training and testing sets with F1 scores close to each other.\n",
        "\n",
        "**Gradient Boosting:**\n",
        "\n",
        "Train F1 Score: 0.766\n",
        "Test F1 Score: 0.764\n",
        "Gradient Boosting performs well on both sets, with slightly higher F1 scores on the training set compared to the test set.\n",
        "\n",
        "**Considerations:**\n",
        "\n",
        "Ensemble models combine multiple base models to improve overall performance.\n",
        "Random Forest builds multiple decision trees and combines their predictions, providing robustness and handling complex relationships in data.\n",
        "AdaBoost focuses on correcting errors made by previous models in the ensemble, giving more weight to misclassified instances.\n",
        "Gradient Boosting builds trees sequentially, with each tree correcting errors of the previous ones, often leading to higher accuracy."
      ],
      "metadata": {
        "id": "s7hTZO8P6oEJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparison of Train and Test F1 Scores for Different Models**"
      ],
      "metadata": {
        "id": "CYN56epa-Cut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# F1 scores for train and test sets for all models\n",
        "train_f1_scores = [model1_train_f1, model2_train_f1, model3_train_f1, model4_train_f1,model4_Hyper_train_f1, model5_rf_train_f1, model5_ada_train_f1,\n",
        "                   model5_gb_train_f1]\n",
        "test_f1_scores = [model1_test_f1, model2_test_f1,model3_test_f1 , model4_test_f1, model4_Hyper_train_f1,model5_rf_test_f1, model5_ada_test_f1,\n",
        "                  model5_gb_test_f1]\n",
        "\n",
        "models = ['Logistic Regression', 'Random Forest', 'KNN', 'XGBoost', 'Hyper_XGBoost' , 'RF', 'AdaBoost', 'Gradient Boosting']\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "bar_width = 0.35\n",
        "index = range(len(models))\n",
        "\n",
        "plt.bar(index, train_f1_scores, width=bar_width, alpha=0.7, label='Train F1 Score')\n",
        "plt.bar([i + bar_width for i in index], test_f1_scores, width=bar_width, alpha=0.7, label='Test F1 Score')\n",
        "\n",
        "# Adding annotations to the bars\n",
        "for i in index:\n",
        "    plt.text(i, train_f1_scores[i] + 0.01, f'{train_f1_scores[i]:.2f}', ha='center', va='bottom')\n",
        "    plt.text(i + bar_width, test_f1_scores[i] + 0.01, f'{test_f1_scores[i]:.2f}', ha='center', va='bottom')\n",
        "\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Comparison of Train and Test F1 Scores for Different Models')\n",
        "plt.xticks([i + bar_width / 2 for i in index], models, rotation=45)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3XFdGNGb8nVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " We have selected XGBoost without hyperparameter tuning based on its better score before tuning."
      ],
      "metadata": {
        "id": "fDy5GrixjeWJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For an imbalanced class dataset F1 score is a more appropriate metric. It is the harmonic mean of precision and recall\n",
        "and the expression is\n",
        "\n",
        "\n",
        "F1= 2*(precision*recall/precision+recall)\n",
        "\n",
        "\n",
        "So, if the classifier predicts the minority class but the prediction is erroneous and false-positive increases, the precision metric will be low and so as F1 score. Also, if the classifier identifies the minority class poorly, i.e. more of this class wrongfully predicted as the majority class then false negatives will increase, so recall and F1 score will low. F1 score only increases if both the number and quality of prediction improves."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final prediction model chosen is XGBoost without hyperparameter tuning. This decision is based on the evaluation metrics, specifically the F1 scores, where the XGBoost model without tuning exhibited superior performance compared to other models.\n",
        "\n",
        "Before Hyperparameter Tuning (XGBoost without tuning):\n",
        "\n",
        "Training F1 Score: 0.8037\n",
        "\n",
        "Testing F1 Score: 0.7665\n",
        "\n",
        "These F1 scores indicate a good balance between precision and recall on both the training and testing datasets. The model demonstrated robust generalization to unseen data, and the relatively high F1 scores suggest effective classification performance. The decision to select XGBoost without hyperparameter tuning is grounded in its strong out-of-the-box performance and the desire to avoid potential overfitting that may result from aggressive hyperparameter adjustments."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For understanding the importance and impact of features in an XGBoost model we have used the feature importance plot above.\n",
        "\n",
        "**Feature Importance:**\n",
        "XGBoost provides a built-in method to measure feature importance based on how frequently features are used in building decision trees during the boosting process. This method ranks features based on their contribution to reducing the impurity (like Gini impurity for classification or variance reduction for regression) across all the trees in the ensemble. You can access feature importance scores using xgboost.plot_importance() or model.feature_importances_ in Python."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, we embarked on a comprehensive data analysis and predictive modeling journey to address the task of email status classification. The key steps involved in the project include data exploration, preprocessing, feature engineering, handling missing values, categorical encoding, outlier detection, scaling, addressing class imbalance, and building and evaluating multiple machine learning models.\n",
        "\n",
        "**1)Data Preprocessing:**\n",
        "\n",
        "Handled missing values using appropriate imputation techniques.\n",
        "Employed one-hot encoding for categorical variables to make them suitable for machine learning models.\n",
        "Addressed multicollinearity by removing correlated features.\n",
        "Detected and handled outliers in the dataset, considering the impact on the imbalanced target variable.\n",
        "\n",
        "**2)Feature Engineering:**\n",
        "\n",
        "Calculated the Variance Inflation Factor (VIF) to identify multicollinearity.\n",
        "Utilized information gain to perform feature selection and dropped less informative features.\n",
        "\n",
        "**3)Class Imbalance:**\n",
        "\n",
        "Recognized the imbalance in the target variable distribution.\n",
        "Employed the Synthetic Minority Over-sampling Technique (SMOTE) to balance the dataset, ensuring a more representative training process.\n",
        "\n",
        "**4)Machine Learning Models:**\n",
        "\n",
        "Developed and evaluated machine learning models including Logistic Regression, Random Forest, K-Nearest Neighbors (KNN), and XGBoost.\n",
        "Utilized ensemble methods like Random Forest, AdaBoost, and Gradient Boosting to explore potential performance improvements.\n",
        "\n",
        "**5)Model Evaluation:**\n",
        "\n",
        "Evaluated models based on F1 score, precision, recall, and accuracy.\n",
        "Visualized precision-recall curves and confusion matrices for deeper insights into model performance.\n",
        "\n",
        "**6)Final Model Selection:**\n",
        "\n",
        "Chose XGBoost without hyperparameter tuning as the final prediction model due to its strong out-of-the-box performance.\n",
        "Considered the balance between precision and recall, as well as the model's ability to generalize to new data.\n",
        "\n",
        "**7)Hyperparameter Tuning:**\n",
        "\n",
        "Conducted hyperparameter tuning for XGBoost using GridSearchCV to explore potential improvements.\n",
        "Observed a reduction in F1 scores after hyperparameter tuning, reinforcing the decision to stick with the initial XGBoost model.\n",
        "\n",
        "**8)Conclusion:**\n",
        "\n",
        "The project demonstrates a systematic approach to address email status classification, covering various aspects of data preprocessing, feature engineering, and model evaluation.\n",
        "The chosen XGBoost model, without hyperparameter tuning, proved to be robust and effective for the given task, showcasing the importance of model selection and understanding the impact of hyperparameter adjustments.\n",
        "Future work could involve exploring additional feature engineering techniques, experimenting with more advanced models, and considering different strategies for handling class imbalance."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}